{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy import spatial\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = \"https://voice-api.dapt.tech\"\n",
    "api_url_stage = \"https://staging-voice-api.dapt.tech\"\n",
    "ml_api = \"http://52.86.72.117:5000/features\"\n",
    "ml_api_compare = \"http://52.86.72.117:5000/compare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = [18, 19, 20, 21, 22, 23, 36, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 50, 52, 53, 56, 57, 58, 61, 62, 64, 66, 68, 69, 70, 71, 72, 78, 79, 80, 82, 83, 84, 85, 86]  # new one started from 36; 80(?); 45 wrong read # another new from \n",
    "user_ids_stage = [10, 23, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get admin tokens\n",
    "username = 'admin'  # put username here\n",
    "password = 'A7mQP4ukB4zdc4cL'  # put password here\n",
    "\n",
    "params = {\n",
    "    \"username\": username,\n",
    "    'password': password\n",
    "}\n",
    "\n",
    "r = requests.post(f'{api_url}/api/v1/auth/login/', json=params)\n",
    "token = r.json().get('access')\n",
    "\n",
    "r = requests.post(f'{api_url_stage}/api/v1/auth/login/', json=params)\n",
    "token_stage = r.json().get('access')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "headers_stage = {\"Authorization\": f\"Bearer {token_stage}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:31<00:00,  1.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# get user info\n",
    "\n",
    "users = []\n",
    "\n",
    "def get_user_info(user_id, api_url, headers):\n",
    "    user_info_url = f\"{api_url}/api/v1/user/{user_id}\"\n",
    "    r = requests.get(user_info_url, headers=headers)\n",
    "    res = r.json()\n",
    "    audio_samples = res.get(\"audio_samples\")\n",
    "    imprint = list(cdict['file'] for cdict in audio_samples if cdict[\"sample_type\"] == \"1\")[0]\n",
    "    checkin = list(cdict['file'] for cdict in audio_samples if cdict[\"sample_type\"] == \"2\")[0]\n",
    "    checkout = list(cdict['file'] for cdict in audio_samples if cdict[\"sample_type\"] == \"3\")[0]\n",
    "    user_info = {\n",
    "        'id': r.json().get('id'),\n",
    "        'imprint': imprint,\n",
    "        'checkin': checkin,\n",
    "        'checkout': checkout\n",
    "    }\n",
    "    return user_info\n",
    "\n",
    "# get from prod\n",
    "for user_id in tqdm(user_ids): \n",
    "    user_info = get_user_info(user_id, api_url, headers)\n",
    "    users.append(user_info)\n",
    "    # print(f'got {user_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:09<00:00,  1.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# get from stage\n",
    "for user_id in tqdm(user_ids_stage): \n",
    "    user_info = get_user_info(user_id, api_url_stage, headers_stage)\n",
    "    users.append(user_info)\n",
    "    # print(f'got {user_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [10:53<00:00, 12.33s/it]\n"
     ]
    }
   ],
   "source": [
    "# get features\n",
    "\n",
    "users_features = []\n",
    "\n",
    "def get_features(api_url, file_url, mean_on=False):\n",
    "    params = {\n",
    "        \"url\": file_url,\n",
    "        'mean': mean_on\n",
    "    }\n",
    "    r = requests.get(api_url, params=params)\n",
    "    res = r.json()\n",
    "    features = res['features']\n",
    "    return features\n",
    "\n",
    "for user in tqdm(users):\n",
    "    try:\n",
    "        user_id = user['id']\n",
    "        # print(f'User {user_id}')\n",
    "        imprint = get_features(ml_api, user['imprint'], mean_on=True)\n",
    "        # print(' got imprint')\n",
    "        checkin = get_features(ml_api, user['checkin'])\n",
    "        # print(' got checkin')\n",
    "        checkout = get_features(ml_api, user['checkout'])\n",
    "        # print(' got checkout')\n",
    "        user_features = {\n",
    "            'id': user['id'],\n",
    "            'imprint': imprint,\n",
    "            'checkin': checkin,\n",
    "            'checkout': checkout\n",
    "        }\n",
    "        users_features.append(user_features)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "        # print(' got exception!!!')\n",
    "    # print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_features in users_features:\n",
    "    user_features['imprint']['d_vector'] = user_features['imprint']['d_vector'][:256]\n",
    "    user_features['checkin']['d_vector'] = user_features['checkin']['d_vector'][:256]\n",
    "    user_features['checkout']['d_vector'] = user_features['checkout']['d_vector'][:256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make random splits of users\n",
    "\n",
    "rs = ShuffleSplit(n_splits=10, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare\n",
    "\n",
    "verification_thresold = 0.69\n",
    "target_names = ['verified', 'rejected']\n",
    "\n",
    "\n",
    "def compare_d_vector_locally(features_1, features_2):\n",
    "    return 1 - spatial.distance.cosine(features_1['d_vector'], features_2['d_vector'])\n",
    "\n",
    "\n",
    "def general_test(users_features, rs, feature_for_compare_1, feature_for_compare_2):\n",
    "    # iterate splits\n",
    "    \n",
    "    accuracies = list()\n",
    "    \n",
    "    for split_idx, (verif_index, reject_index) in enumerate(rs.split(users_features)):\n",
    "        clear_output(wait=True)\n",
    "        print(f'SPLIT {split_idx}')\n",
    "        labels = list()\n",
    "        preds = list()\n",
    "\n",
    "        for idx, user in enumerate(users_features):\n",
    "            if idx in verif_index:\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "\n",
    "            user_id = user['id']    \n",
    "            similarities = []\n",
    "            for idx2, user2 in enumerate(users_features):\n",
    "                if idx2 in verif_index:\n",
    "                    user_id_2 = user2['id']\n",
    "                    similarity = compare_d_vector_locally(user[feature_for_compare_1], user2[feature_for_compare_2])\n",
    "                    similarities.append(similarity)\n",
    "                else:\n",
    "                    similarities.append(0)\n",
    "\n",
    "            # choose most similar\n",
    "            max_similarity = max(similarities)\n",
    "            most_similar_idx = similarities.index(max_similarity)\n",
    "\n",
    "            if max_similarity > verification_thresold:\n",
    "                if idx in verif_index:\n",
    "                    # check\n",
    "                    if most_similar_idx == idx:\n",
    "                        preds.append(0)\n",
    "                    else:\n",
    "                        preds.append(1)\n",
    "                else:\n",
    "                    preds.append(0)\n",
    "            else:\n",
    "                preds.append(1)\n",
    "        report = classification_report(labels, preds, target_names=target_names)\n",
    "        print(report)\n",
    "        report = classification_report(labels, preds, target_names=target_names, output_dict=True)\n",
    "        accuracies.append(report.get('accuracy'))\n",
    "        # time.sleep(2)\n",
    "\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    print(f'\\n\\nMean accuracy: {mean_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    verified       0.93      0.84      0.88        44\n",
      "    rejected       0.22      0.40      0.29         5\n",
      "\n",
      "    accuracy                           0.80        49\n",
      "   macro avg       0.57      0.62      0.58        49\n",
      "weighted avg       0.85      0.80      0.82        49\n",
      "\n",
      "\n",
      "\n",
      "Mean accuracy: 0.7959183673469388\n"
     ]
    }
   ],
   "source": [
    "general_test(users_features, rs, 'imprint', 'checkin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    verified       0.93      0.89      0.91        44\n",
      "    rejected       0.29      0.40      0.33         5\n",
      "\n",
      "    accuracy                           0.84        49\n",
      "   macro avg       0.61      0.64      0.62        49\n",
      "weighted avg       0.86      0.84      0.85        49\n",
      "\n",
      "\n",
      "\n",
      "Mean accuracy: 0.826530612244898\n"
     ]
    }
   ],
   "source": [
    "general_test(users_features, rs, 'imprint', 'checkout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    verified       0.95      0.91      0.93        44\n",
      "    rejected       0.43      0.60      0.50         5\n",
      "\n",
      "    accuracy                           0.88        49\n",
      "   macro avg       0.69      0.75      0.72        49\n",
      "weighted avg       0.90      0.88      0.89        49\n",
      "\n",
      "\n",
      "\n",
      "Mean accuracy: 0.883673469387755\n"
     ]
    }
   ],
   "source": [
    "general_test(users_features, rs, 'checkin', 'checkout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    verified       0.98      0.95      0.97        44\n",
      "    rejected       0.67      0.80      0.73         5\n",
      "\n",
      "    accuracy                           0.94        49\n",
      "   macro avg       0.82      0.88      0.85        49\n",
      "weighted avg       0.95      0.94      0.94        49\n",
      "\n",
      "\n",
      "\n",
      "Mean accuracy: 0.9102040816326531\n"
     ]
    }
   ],
   "source": [
    "general_test(users_features, rs, 'checkout', 'checkin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    verified       0.93      0.91      0.92        44\n",
      "    rejected       0.33      0.40      0.36         5\n",
      "\n",
      "    accuracy                           0.86        49\n",
      "   macro avg       0.63      0.65      0.64        49\n",
      "weighted avg       0.87      0.86      0.86        49\n",
      "\n",
      "\n",
      "\n",
      "Mean accuracy: 0.8734693877551021\n"
     ]
    }
   ],
   "source": [
    "general_test(users_features, rs, 'checkin', 'imprint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    verified       0.95      0.95      0.95        44\n",
      "    rejected       0.60      0.60      0.60         5\n",
      "\n",
      "    accuracy                           0.92        49\n",
      "   macro avg       0.78      0.78      0.78        49\n",
      "weighted avg       0.92      0.92      0.92        49\n",
      "\n",
      "\n",
      "\n",
      "Mean accuracy: 0.8775510204081634\n"
     ]
    }
   ],
   "source": [
    "general_test(users_features, rs, 'checkout', 'imprint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
